}
}
# Normative alignment stuff
df.demo = df.demo %>% mutate(
norm.h1.actual.div = abs(actual.h1.prob - norm.h1),
norm.h2.actual.div = abs(actual.h2.prob - norm.h2),
norm.h3.actual.div = abs(actual.h3.prob - norm.h3),
norm.h1.actual.dichotomized = norm.h1.dichotomized == actual.h1.prob.dichotomized,
norm.h2.actual.dichotomized = norm.h2.dichotomized == actual.h2.prob.dichotomized,
norm.h3.actual.dichotomized = norm.h3.dichotomized == actual.h3.prob.dichotomized) %>%
rowwise() %>% mutate(
norm.actual.div = mean(c(norm.h1.actual.div, norm.h2.actual.div, norm.h3.actual.div)),
norm.actual.dichotomized = mean(c(norm.h1.actual.dichotomized, norm.h2.actual.dichotomized, norm.h3.actual.dichotomized))
)
rm(fitting_results)
exclude.subj = c()
for (subj in subjlist) {
demo.row = df.demo$subject == subj
s1.subj = df.s1.subj$subject == subj
browser.row = df.browser.subj$subject == subj
if (df.demo$instruction_times_median[demo.row] < 2 || # if they took, on average, <2 sec per instruction screen
df.s1.subj$num_trials[s1.subj] != numTrials | # if they didn't complete all the trials
df.demo$attention[demo.row] < 50 | # if they reported themselves as having paid less than 50% attention
df.demo$cc.correct.total[demo.row] < 4 | # if they got fewer than 4/6 comprehension checks correct
(df.demo$did_two[demo.row] & df.demo$which_version_first[demo.row] != version) |
df.attributes.subj$num_same[df.attributes.subj$subject == subj] > 0 |
#df.demo$cv_result[demo.row] < .5 |
(any(browser.row) & df.browser.subj$num.blur[df.browser.subj$subject == subj] > 20)) { # if they tabbed away from the experiment more than 20 times
exclude.subj = c(exclude.subj, subj)
}
if (participant_type == 'decider') {
if (df.s1.subj$pct_left[s1.subj] > .8 | # if they chose the left or right option >80% of the time
df.s1.subj$pct_left[s1.subj] < .2) {
exclude.subj = c(exclude.subj, subj)
}
} else {
if (df.s1.subj$pct_correct[s1.subj] < 0.95 |
is.na(df.demo$decider.subj.num[demo.row])) {
exclude.subj = c(exclude.subj, subj)
}
}
}
df.demo.filt = df.demo %>% filter(!(subject %in% exclude.subj))
df.s1.filt = df.s1 %>% filter(!(subject %in% exclude.subj))
df.s1.subj.filt = df.s1.subj %>% filter(!(subject %in% exclude.subj))
df.s1.practice.filt = df.s1.practice %>% filter(!(subject %in% exclude.subj))
df.s2.filt = df.s2 %>% filter(!(subject %in% exclude.subj))
df.attributes.filt = df.attributes %>% filter(!(subject %in% exclude.subj))
df.attributes.subj.filt = df.attributes.subj %>% filter(!(subject %in% exclude.subj))
df.cc.filt = df.cc %>% filter(!(subject %in% exclude.subj))
df.cc.subj.filt = df.cc.subj %>% filter(!(subject %in% exclude.subj))
ggplot(df.demo.filt, aes(x = weight.accuracy.averaged)) +
geom_histogram(color = 'gray') +
#geom_vline(xintercept = mean(rand.errs), color = 'gray') +
geom_vline(xintercept = mean(df.demo.filt$weight.accuracy.averaged, na.rm = T), color = 'red') +
geom_vline(xintercept = mean(df.demo.filt$weight.accuracy.averaged, na.rm = T)+se(df.demo.filt$weight.accuracy.averaged), color = 'red', linetype = 'dashed') +
geom_vline(xintercept = mean(df.demo.filt$weight.accuracy.averaged, na.rm = T)-se(df.demo.filt$weight.accuracy.averaged), color = 'red', linetype = 'dashed') +
labs(x = 'Participant-level correlation between\nfitted and reported weights', y = '# of subjects') +
#labs(x = '', y = '') +
scale_y_continuous(breaks = NULL) +
#scale_x_continuous(limits = c(-.2, 1.1), breaks = c(0, .5, 1)) +
theme_black()
fitting_results[[1]][[1]]
fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
fitting_results[[1]][[1]][[1]]
fitting_results[[100]][[1]][[1]]
#fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
load(paste0(filepath, 'modeling_output.rdata'))
fitting_results[[1]][[1]][[1]]
fitting_results[[100]][[1]][[1]]
directory = paste0(filepath, 'modeling-output/')
# Get a list of .RData files in the directory
files <- list.files(directory, pattern="\\.rdata$", full.names=TRUE)
files
# Sort the files by the numbers in their names
files <- files[order(as.numeric(gsub("^modeling_output_|\\.rdata$", "", files)))]
files
length(files)
paste0(directory, 'modeling_output_', 1, '.rdata')
i = 1
load(paste0(directory, 'modeling_output_', 1, '.rdata'))
# for loading model fitting results
combine_lists <- function(directory) {
# Get a list of .RData files in the directory
files <- list.files(directory, pattern="\\.rdata$", full.names=TRUE)
# Create an empty list to store the data
all_data <- list()
# Load the data from each file
for (i in 1:length(files)) {
load(paste0(directory, 'modeling_output_', 1, '.rdata'))
all_data <- c(all_data, fitting_results_split_cur)
}
return(all_data)
}
fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
# for loading model fitting results
combine_lists <- function(directory) {
# Get a list of .RData files in the directory
files <- list.files(directory, pattern="\\.rdata$", full.names=TRUE)
# Create an empty list to store the data
all_data <- list()
# Load the data from each file
for (i in 1:length(files)) {
load(paste0(directory, 'modeling_output_', i, '.rdata'))
all_data <- c(all_data, fitting_results_split_cur)
}
return(all_data)
}
fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
fitting_results[[100]][[1]][[1]]
combine_lists
# for loading model fitting results
combine_lists <- function(directory) {
# Get a list of .RData files in the directory
files <- list.files(directory, pattern="\\.rdata$", full.names=TRUE)
# Create an empty list to store the data
all_data <- list()
# Load the data from each file
for (i in 1:length(files)) {
load(paste0(directory, 'modeling_output_', i, '.rdata'))
all_data <- c(all_data, fitting_results_split_cur)
}
return(all_data)
}
fitting_results[[100]][[1]][[1]]
fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
fitting_results[[100]][[1]][[1]]
rm(list=ls())
gc()
gc()
# if (!require('pacman')) {
#   install.packages('pacman')
#   require('pacman')
# }
require(groundhog)
pkg.names = c('ggplot2', 'lme4', 'lmerTest', 'tidyverse', 'jsonlite', 'combinat', 'effectsize', 'RColorBrewer', 'scales')
#groundhog.library(pkg.names, '2023-03-11')
lapply(pkg.names, require, character.only = TRUE)
theme_update(strip.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
plot.background = element_blank(),
axis.text=element_text(size=25, colour = "black"),
axis.title=element_text(size=30, face = "bold"),
axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"),
legend.text = element_text(size = 20),
plot.title = element_text(size = 26, face = "bold", vjust = 1),
panel.margin = unit(1.0, "lines"),
plot.margin = unit(c(0.5,  0.5, 0.5, 0.5), "lines"),
axis.line = element_line(colour = "black", size = 2),
axis.ticks = element_line(color = 'black', size = 3),
axis.ticks.length = unit(.25, 'cm')
)
theme_black = function(base_size = 12, base_family = "") {
theme_grey(base_size = base_size, base_family = base_family) %+replace%
theme(
# Specify axis options
axis.line = element_blank(),
axis.text.x = element_text(size = 12, color = "white", lineheight = 0.9),
axis.text.y = element_text(size = 12, color = "white", lineheight = 0.9),
axis.ticks = element_line(color = "white", size  =  0.2),
axis.title.x = element_text(size = 18, color = "white", margin = margin(0, 10, 0, 0)),
axis.title.y = element_text(size = 18, color = "white", angle = 90, margin = margin(0, 10, 0, 0)),
axis.ticks.length = unit(0.3, "lines"),
# Specify legend options
legend.background = element_rect(color = NA, fill = "black"),
legend.key = element_rect(color = "white",  fill = "black"),
legend.key.size = unit(1.2, "lines"),
legend.key.height = NULL,
legend.key.width = NULL,
legend.text = element_text(size = base_size*0.8, color = "white"),
legend.title = element_text(size = base_size*0.8, face = "bold", hjust = 0, color = "white"),
legend.position = "right",
legend.text.align = NULL,
legend.title.align = NULL,
legend.direction = "vertical",
legend.box = NULL,
# Specify panel options
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
panel.border = element_rect(fill = NA, color = "white"),
# Specify facetting options
strip.background = element_rect(fill = "grey30", color = "grey10"),
strip.text.x = element_text(size = base_size*0.8, color = "white"),
strip.text.y = element_text(size = base_size*0.8, color = "white",angle = -90),
# Specify plot options
plot.background = element_rect(color = "black", fill = "black"),
plot.title = element_text(size = base_size*1.2, color = "white"),
plot.margin = unit(rep(1, 4), "lines")
)
}
se = function(x) {return(sd(x, na.rm = T) / sqrt(sum(!is.na(x))))}
se.prop = function(x) {return(sqrt(mean(x, na.rm = T) * (1-mean(x, na.rm = T)) / sum(!is.na(x))))}
get.ci = function(x) {return(c(mean(x,na.rm = T) - 1.96*se(x), mean(x, na.rm = T), mean(x, na.rm = T) + 1.96*se(x)))}
get.ci.prop = function(x) {return(c(mean(x,na.rm = T) - 1.96*se.prop(x), mean(x, na.rm = T), mean(x, na.rm = T) + 1.96*se.prop(x)))}
as.string.vector = function(x) {
return(strsplit(x,',')[[1]])
}
as.numeric.vector = function(x) {
return(as.numeric(strsplit(gsub('\\[|\\]','',x),',')[[1]]))
}
as.string = function(x) {
return(paste(x, collapse = ','))
}
dodge <- position_dodge(width=0.9)
# for loading model fitting results
combine_lists <- function(directory) {
# Get a list of .RData files in the directory
files <- list.files(directory, pattern="\\.rdata$", full.names=TRUE)
# Create an empty list to store the data
all_data <- list()
# Load the data from each file
for (i in 1:length(files)) {
load(paste0(directory, 'modeling_output_', i, '.rdata'))
all_data <- c(all_data, fitting_results_split_cur)
}
return(all_data)
}
# Only works in RStudio -- otherwise you have to set the path manually
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("/Users/adam/Me/Psychology/Projects/ma_choice/git3/data-analysis/home-fixed/analysis_output.rdata")
#fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
load(paste0(filepath, 'modeling_output.rdata'))
fitting_results[[100]][[1]][[1]]
# Model-fitting is done in "fit-subjects.R"
if (participant_type == 'decider') {
fitting_results = combine_lists(paste0(filepath, 'modeling-output/'))
decider.names = df.demo$subject
decider.nums = df.demo$subject.num
} else { # observer stuff
fitting_results = combine_lists(paste0(filepath_decider, 'modeling-output/'))
## Load the subject mapping data (which should have been saved from the decider analysis)
df.map = read.csv(paste0(filepath, 'observer_mapping.csv'), header = F)
colnames(df.map) = c('subject', 'subject.num')
decider.names = df.map$subject
decider.nums = df.map$subject.num
}
## model comparison
# values to extract:
# best model for each subject, posterior probability of that model, lme of that model
# posterior & lme for reported model
# posterior for each model
# prob for each of the three properties
# loo results
# diagnostic results
numHeuristics <- 3
heuristic_families <- list(
list(1:4, 5:6),
list(1:2, 3:4),
list(c(1,3,5), c(2,4,6))
)
df.demo$actual.model.num = NA
df.demo$actual.model.prob = NA
df.demo$actual.model.lme = NA
df.demo$actual.inv.temp = NA
df.demo$actual.model.loo = NA
df.demo$actual.model.diagnostics = NA
df.demo$process.accuracy.model.prob = NA
df.demo$reported.model.lme = NA
df.demo$norm.model.prob = NA
numSubj = length(subjlist)
model_weights = vector(mode='list', length = numSubj)
for (s in 1:numSubj) {
decider.num = ifelse(participant_type == 'decider',
s,
df.demo$target_id_num[s])
if (length(decider.num) > 0) {
df.demo$decider.subj.num[s] = decider.num
model_temps = rep(NA,length(models))
model_weights[[s]] = matrix(NA, nrow = length(models), ncol = numAtts)
colnames(model_weights[[s]]) = atts
model_probs = rep(NA,length(models))
model_lmes = rep(NA,length(models))
for (m in 1:length(models)) {
if (!is.null(fitting_results[[decider.num]][[1]])) {
params_cur = fitting_results[[decider.num]][[m]][[1]]
model_temps[m] = params_cur[1]
model_weights[[s]][m,] = params_cur[2:(numAtts+1)]
model_lmes[m] = fitting_results[[decider.num]][[m]][[2]]
}
}
model_mes = exp(model_lmes)
model_probs = model_mes / sum(model_mes)
for (m in 1:length(models)) {
df.demo[s,paste0('model.', models[m], '.prob')] = model_probs[m]
}
if (any(!is.na(model_probs))) {
# stats of best-fitting model
df.demo$actual.model.num[s] = which.max(model_probs)
df.demo$actual.model.prob[s] = max(model_probs)
df.demo$actual.model.lme[s] = model_lmes[df.demo$actual.model.num[s]]
df.demo$actual.inv.temp[s] = model_temps[df.demo$actual.model.num[s]]
df.demo$actual.model.loo[s] = fitting_results[[decider.num]][[df.demo$actual.model.num[s]]][[5]]$estimates[1,1]
df.demo$actual.model.diagnostics[s] = fitting_results[[decider.num]][[df.demo$actual.model.num[s]]][4]
# stats of reported model
df.demo$process.accuracy.model.prob[s] = model_probs[df.demo$reported.model.num[s]]
df.demo$reported.model.lme[s] = model_lmes[df.demo$reported.model.num[s]]
# stats of norm model
df.demo$norm.model.prob[s] = model_probs[df.demo$reported.model.num[s]]
}
# property questions
for (heuristic in 1:numHeuristics) {
df.demo[s, paste0('actual.h', heuristic, '.prob')] = mean(model_mes[heuristic_families[[heuristic]][[2]]]) / (mean(model_mes[heuristic_families[[heuristic]][[1]]]) + mean(model_mes[heuristic_families[[heuristic]][[2]]]))
}
} else {
df.demo$decider.subj.num[s] = NA
}
}
ll.chance = log(.5 ^ numTrials)
df.demo = df.demo %>%
mutate(actual.model = models[actual.model.num],
actual.model.fac = factor(actual.model, models.order, models.order),
process.accuracy.model.dichotomized = reported.model.num == actual.model.num,
norm.model.dichotomized = norm.model.num == actual.model.num,
process.accuracy.div.h1 = abs(actual.h1.prob - reported.h1),
process.accuracy.div.h2 = abs(actual.h2.prob - reported.h2),
process.accuracy.div.h3 = abs(actual.h3.prob - reported.h3),
actual.h1.prob.dichotomized = actual.h1.prob > 0.5,
actual.h2.prob.dichotomized = actual.h2.prob > 0.5,
actual.h3.prob.dichotomized = actual.h3.prob > 0.5,
process.accuracy.h1.dichotomized = reported.h1.dichotomized == actual.h1.prob.dichotomized,
process.accuracy.h2.dichotomized = reported.h2.dichotomized == actual.h2.prob.dichotomized,
process.accuracy.h3.dichotomized = reported.h3.dichotomized == actual.h3.prob.dichotomized,
process.accuracy.model.relprob = process.accuracy.model.prob / actual.model.prob,
norm.model.relprob = norm.model.prob / actual.model.prob,
actual.model.loo.readable = exp(actual.model.loo/numTrials)) %>%
rowwise() %>% mutate(
process.accuracy.div = mean(c(process.accuracy.div.h1, process.accuracy.div.h2, process.accuracy.div.h3)),
process.accuracy.qs.dichotomized = mean(c(process.accuracy.h1.dichotomized, process.accuracy.h2.dichotomized, process.accuracy.h3.dichotomized)),
)
## weights
for (i in 1:nrow(df.attributes)) {
rows.demo = as.character(df.demo$subject) == as.character(df.attributes$subject[i])
df.attributes$actual.model.num[i] = df.demo$actual.model.num[rows.demo]
df.attributes$reported.weight.actual[i] = ifelse(df.demo$actual.h1.prob.dichotomized[rows.demo],
df.attributes$reported.weight.single[i],
ifelse(df.demo$actual.h2.prob.dichotomized[rows.demo],
df.attributes$reported.weight.binary[i],
df.attributes$reported.weight.graded[i]))
df.attributes$fitted.weight.reported[i] = model_weights[[df.attributes$subject.num[i]]][df.attributes$reported.model.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.actual[i] = model_weights[[df.attributes$subject.num[i]]][df.attributes$actual.model.num[i],df.attributes$attribute[i]]
model.prob = numeric(length(models))
model.att = numeric(length(models))
for (m in 1:length(models)) {
df.attributes[i, paste0('fitted.weight.', models[m])] = model_weights[[df.attributes$subject.num[i]]][m,df.attributes$attribute[i]]
model.att[m] = df.attributes[i, paste0('fitted.weight.', models[m])]
model.prob[m] = df.demo[rows.demo, paste0('model.', models[m], '.prob')][[1]]
}
df.attributes$fitted.weight.averaged[i] = sum(model.prob * model.att)
df.attributes$reported.weight.averaged[i] = sum(model.prob * c(df.attributes$reported.weight.graded[i], df.attributes$reported.weight.graded[i],
df.attributes$reported.weight.binary[i], df.attributes$reported.weight.binary[i],
df.attributes$reported.weight.single[i], df.attributes$reported.weight.single[i]))
}
df.attributes = df.attributes %>% mutate(reported.weight.actual.signed = reported.weight.actual * direction,
reported.weight.averaged.signed = reported.weight.averaged * direction,
reported.weight.reported.signed = reported.weight.reported * direction)
# get subject-level accuracies
df.attributes.subj = df.attributes %>% group_by(subject) %>%
summarize(num_same = sum(same & (reported.weight.graded > .1), na.rm = T),
weight.accuracy.reported = cor(fitted.weight.reported, reported.weight.reported.signed),
weight.accuracy.reported.rank = cor(fitted.weight.reported, reported.weight.reported.signed, method = 'kendall'),
weight.accuracy.best = cor(fitted.weight.actual, reported.weight.actual.signed),
weight.accuracy.best.rank = cor(fitted.weight.actual, reported.weight.actual.signed, method = 'kendall'),
weight.accuracy.averaged = cor(fitted.weight.averaged, reported.weight.averaged.signed),
weight.accuracy.averaged.rank = cor(fitted.weight.averaged, reported.weight.averaged.signed, method = 'kendall')
)
# transfer these to df.demo
cols.to.xfer = colnames(df.attributes.subj %>% select(!subject))
for (i in 1:nrow(df.demo)) {
att.row = df.attributes.subj$subject == df.demo$subject[i]
for (cur.col in cols.to.xfer) {
df.demo[i,cur.col] = df.attributes.subj[att.row, cur.col]
}
}
# Normative alignment stuff
df.demo = df.demo %>% mutate(
norm.h1.actual.div = abs(actual.h1.prob - norm.h1),
norm.h2.actual.div = abs(actual.h2.prob - norm.h2),
norm.h3.actual.div = abs(actual.h3.prob - norm.h3),
norm.h1.actual.dichotomized = norm.h1.dichotomized == actual.h1.prob.dichotomized,
norm.h2.actual.dichotomized = norm.h2.dichotomized == actual.h2.prob.dichotomized,
norm.h3.actual.dichotomized = norm.h3.dichotomized == actual.h3.prob.dichotomized) %>%
rowwise() %>% mutate(
norm.actual.div = mean(c(norm.h1.actual.div, norm.h2.actual.div, norm.h3.actual.div)),
norm.actual.dichotomized = mean(c(norm.h1.actual.dichotomized, norm.h2.actual.dichotomized, norm.h3.actual.dichotomized))
)
rm(fitting_results)
fitting_results[[100]][[1]][[1]]
exclude.subj = c()
for (subj in subjlist) {
demo.row = df.demo$subject == subj
s1.subj = df.s1.subj$subject == subj
browser.row = df.browser.subj$subject == subj
if (df.demo$instruction_times_median[demo.row] < 2 || # if they took, on average, <2 sec per instruction screen
df.s1.subj$num_trials[s1.subj] != numTrials | # if they didn't complete all the trials
df.demo$attention[demo.row] < 50 | # if they reported themselves as having paid less than 50% attention
df.demo$cc.correct.total[demo.row] < 4 | # if they got fewer than 4/6 comprehension checks correct
(df.demo$did_two[demo.row] & df.demo$which_version_first[demo.row] != version) |
df.attributes.subj$num_same[df.attributes.subj$subject == subj] > 0 |
#df.demo$cv_result[demo.row] < .5 |
(any(browser.row) & df.browser.subj$num.blur[df.browser.subj$subject == subj] > 20)) { # if they tabbed away from the experiment more than 20 times
exclude.subj = c(exclude.subj, subj)
}
if (participant_type == 'decider') {
if (df.s1.subj$pct_left[s1.subj] > .8 | # if they chose the left or right option >80% of the time
df.s1.subj$pct_left[s1.subj] < .2) {
exclude.subj = c(exclude.subj, subj)
}
} else {
if (df.s1.subj$pct_correct[s1.subj] < 0.95 |
is.na(df.demo$decider.subj.num[demo.row])) {
exclude.subj = c(exclude.subj, subj)
}
}
}
df.demo.filt = df.demo %>% filter(!(subject %in% exclude.subj))
df.s1.filt = df.s1 %>% filter(!(subject %in% exclude.subj))
df.s1.subj.filt = df.s1.subj %>% filter(!(subject %in% exclude.subj))
df.s1.practice.filt = df.s1.practice %>% filter(!(subject %in% exclude.subj))
df.s2.filt = df.s2 %>% filter(!(subject %in% exclude.subj))
df.attributes.filt = df.attributes %>% filter(!(subject %in% exclude.subj))
df.attributes.subj.filt = df.attributes.subj %>% filter(!(subject %in% exclude.subj))
df.cc.filt = df.cc %>% filter(!(subject %in% exclude.subj))
df.cc.subj.filt = df.cc.subj %>% filter(!(subject %in% exclude.subj))
ggplot(df.demo.filt, aes(x = weight.accuracy.averaged)) +
geom_histogram(color = 'gray') +
#geom_vline(xintercept = mean(rand.errs), color = 'gray') +
geom_vline(xintercept = mean(df.demo.filt$weight.accuracy.averaged, na.rm = T), color = 'red') +
geom_vline(xintercept = mean(df.demo.filt$weight.accuracy.averaged, na.rm = T)+se(df.demo.filt$weight.accuracy.averaged), color = 'red', linetype = 'dashed') +
geom_vline(xintercept = mean(df.demo.filt$weight.accuracy.averaged, na.rm = T)-se(df.demo.filt$weight.accuracy.averaged), color = 'red', linetype = 'dashed') +
labs(x = 'Participant-level correlation between\nfitted and reported weights', y = '# of subjects') +
#labs(x = '', y = '') +
scale_y_continuous(breaks = NULL) +
#scale_x_continuous(limits = c(-.2, 1.1), breaks = c(0, .5, 1)) +
theme_black()
get.ci(df.demo.filt$weight.accuracy.averaged)
rm(list=ls())
load("/Users/adam/Me/Psychology/Projects/ma_choice/git3/data-analysis/home-random/modeling_output.rdata")
## which version do we want?
# note that we don't fit observers
versions = c('home-fixed', 'home-random', 'movie')
version = versions[2]
filepath = paste0(here(), '/', version, '/')
filepath
# Split so that each saved data file is <100mb
fitting_results_split = split(fitting_results, ceiling(seq_along(fitting_results) / 20))
for (i in 1:length(fitting_results_split)) {
fitting_results_split_cur = fitting_results_split[[i]]
save(numAtts, option_diffs_touse, choices_touse, filepath,
stan.seed, numChains, numIter,
generateChoices, fitSubj,
fitting_results_split_cur,
file = paste0(filepath, 'modeling-output/modeling_output_', i, '.rdata'))
}
i
for (i in 7:length(fitting_results_split)) {
fitting_results_split_cur = fitting_results_split[[i]]
save(numAtts, option_diffs_touse, choices_touse, filepath,
stan.seed, numChains, numIter,
generateChoices, fitSubj,
fitting_results_split_cur,
file = paste0(filepath, 'modeling-output/modeling_output_', i, '.rdata'))
}
numSubj
rm(list=ls())
version = versions[3]
## which version do we want?
# note that we don't fit observers
versions = c('home-fixed', 'home-random', 'movie')
version = versions[3]
filepath = paste0(here(), '/', version, '/')
load(paste0(filepath,'analysis_output.rdata'))
numSubj = length(subjlist)
numAtts = length(atts)
numSubj
# Do model-fitting --------------------------------------------------------
numCores = 4
fitting_results = mclapply(
1:4,
function(subj) {return(fitAllModels(option_diffs_touse[[subj]], choices_touse[[subj]], full_output = TRUE))},
mc.cores = numCores
)
numSubj = length(subjlist)
numAtts = length(atts)
source(paste0(here(),'/model-fitting/model-fitting.R'))
stan_model_full <- stan_model(paste0(here(),"/model-fitting/stan-program.stan"))
stan_model_binwts <- stan_model(paste0(here(),"/model-fitting/stan-program-binwts.stan"))
# Do model-fitting --------------------------------------------------------
numCores = 4
option_diffs_allsubj = vector(mode = 'list', numSubj)
for (subj in 1:numSubj) {
option_diffs_allsubj[[subj]] = t(as.matrix(df.s1 %>%
filter(subject == subjlist[subj]) %>%
select(all_of(atts.opt.scaled.diff))))
}
option_diffs_touse = option_diffs_allsubj
save(option_diffs_allsubj, file = paste0(here(), '/model-fitting/option_diffs.rdata')) # save for simulations
choices_touse = vector(mode = 'list', numSubj)
for (subj in 1:numSubj) {
choices_touse[[subj]] = df.s1[df.s1$subject == subjlist[subj],'choice']
}
## FIT FULL
begin = Sys.time()
fitting_results = mclapply(
1:4,
function(subj) {return(fitAllModels(option_diffs_touse[[subj]], choices_touse[[subj]], full_output = TRUE))},
mc.cores = numCores
)
